<!DOCTYPE html><html lang="en"><head><meta charset="utf-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="google-site-verification" content="xBT4GhYoi5qRD5tr338pgPM5OWHHIDR6mNg1a3euekI"><meta name="baidu-site-verification" content="093lY4ziMu"><meta name="viewport" content="width=device-width,initial-scale=1,user-scalable=no"><meta name="description" content="聂伟星个人技术博客"><meta name="keyword" content="聂伟星，博客"><link rel="shortcut icon" href="/img/ironman-draw.png"><script async defer="defer" src="https://buttons.github.io/buttons.js"></script><title>Kubernetes之调度篇 - 聂伟星个人技术博客</title><link rel="canonical" href="https://www.niewx.cn/2020/08/26/Kubernetes-scheduling/"><link rel="stylesheet" href="../../../../css/bootstrap.min.css"><link rel="stylesheet" href="../../../../css/dusign-dark.css"><link rel="stylesheet" href="../../../../css/dusign-common-dark.css"><link rel="stylesheet" href="../../../../css/font-awesome.css"><link rel="stylesheet" href="../../../../css/toc.css"><link rel="stylesheet" href="../../../../css/highlight.css"><link rel="stylesheet" href="../../../../css/widget.css"><link rel="stylesheet" href="../../../../css/rocket.css"><link rel="stylesheet" href="../../../../css/signature.css"><link rel="stylesheet" href="../../../../css/fonts.googleapis.css"><link rel="stylesheet" href="//cdn.bootcss.com/font-awesome/4.3.0/css/font-awesome.min.css"><link rel="stylesheet" href="../../../../css/photography.css"><script></script><meta name="generator" content="Hexo 4.2.1"></head><body ontouchstart=""><style type="text/css">header.intro-header{background-image:linear-gradient(rgba(0,0,0,.3),rgba(0,0,0,.5)),url(snail-bg.jpg)}</style><header class="intro-header"><div id="signature"><div class="container"><div class="row"><div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1"><div class="post-heading"><div class="tags"><a class="tag" href="/tags/#Kubernetes" title="Kubernetes">Kubernetes</a></div><h1>Kubernetes之调度篇</h1><h2 class="subheading"></h2><span class="meta">Posted by VashonNie on 2020-08-26</span><div class="blank_box"></div><span class="meta">Words <span class="post-count">6.4k</span> and Reading Time <span class="post-count">26</span> Minutes</span><div class="blank_box"></div><span class="meta">Viewed <span id="busuanzi_value_page_pv"><i class="fa fa-spinner fa-spin"></i></span> Times</span></div></div></div></div></div><div class="waveWrapper"><div class="wave wave_before" style="background-image:url(/img/wave-dark.png)"></div><div class="wave wave_after" style="background-image:url(/img/wave-dark.png)"></div></div></header><nav class="navbar navbar-default navbar-custom navbar-fixed-top"><div class="container-fluid"><div class="navbar-header page-scroll"><button type="button" class="navbar-toggle"><span class="sr-only">Toggle navigation</span> <span class="icon-bar"></span> <span class="icon-bar"></span> <span class="icon-bar"></span></button> <a class="navbar-brand" href="/">聂伟星</a></div><div id="huxblog_navbar"><div class="navbar-collapse"><ul class="nav navbar-nav navbar-right"><li><a href="/">Home</a></li><li><a href="/about/">About</a></li><li><a href="/archive/">Archives</a></li><li><a href="/categories/">Categories</a></li><li><a href="/photography/">Photography</a></li><li><a href="/tags/">Tags</a></li><li><a href="/random.html">Random Post</a></li><li><a href="https://www.niewx.cn/mybook/" target="_blank">Gitbook</a></li></ul></div></div></div></nav><script>var $body=document.body,$toggle=document.querySelector(".navbar-toggle"),$navbar=document.querySelector("#huxblog_navbar"),$collapse=document.querySelector(".navbar-collapse");function handleMagic(e){0<$navbar.className.indexOf("in")?($navbar.className=" ",setTimeout(function(){$navbar.className.indexOf("in")<0&&($collapse.style.height="0px")},400)):($collapse.style.height="auto",$navbar.className+=" in")}$toggle.addEventListener("click",handleMagic)</script><article><div class="container"><div class="row"><div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1 post-container"><p>我们在日常使用k8s的过程中总会存在一些特殊的调度情景：</p><ul><li>让master节点上不部署业务的pod</li><li>让mysql调度到高IO的节点上</li><li>让coredns的服务均匀的散布在每个节点</li><li>让内服服务调度在一个节点上，减少访问延迟</li></ul><p>这边肯定会有其他场景也会有对pod的调度有特殊要求，这边只是列举了其中几个情况，对于上述遇到的情况我们需要怎么处理，其实k8s给我们提供了丰富的调度策略来满足我们的需求。下面我们来一一说下这些调度策略。</p><h1 id="nodeSelector"><a href="#nodeSelector" class="headerlink" title="nodeSelector"></a>nodeSelector</h1><p>你可以约束一个Pod只能在特定的Node(s)上运行，或者优先运行在特定的节点上。有几种方法可以实现这点，推荐的方法都是用标签选择器来进行选择。通常这样的约束不是必须的，因为调度器将自动进行合理的放置（比如，将 pod 分散到节点上，而不是将 pod 放置在可用资源不足的节点上等等），但在某些情况下，你可以需要更多控制 pod 停靠的节点，例如，确保 pod 最终落在连接了 SSD 的机器上，或者将来自两个不同的服务且有大量通信的 pod 放置在同一个可用区</p><p>nodeSelector是节点选择约束的最简单推荐形式。nodeSelector是 PodSpec 的一个字段。 它包含键值对的映射。为了使 pod 可以在某个节点上运行，该节点的标签中必须包含这里的每个键值对（它也可以具有其他标签）。最常见的用法的是一对键值对。</p><h2 id="添加标签到节点"><a href="#添加标签到节点" class="headerlink" title="添加标签到节点"></a>添加标签到节点</h2><p>执行 kubectl get nodes 命令获取集群的节点名称。 选择一个你要增加标签的节点，然后执行命令将标签添加到你所选择的节点上。</p><figure class="highlight delphi"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl <span class="keyword">label</span> nodes &lt;node-<span class="keyword">name</span>&gt; &lt;<span class="keyword">label</span>-key&gt;=&lt;<span class="keyword">label</span>-value&gt;</span><br></pre></td></tr></table></figure><p>例如，如果你的节点名称为 ‘kubernetes-foo-node-1.c.a-robinson.internal’ 并且想要的标签是 ‘disktype=ssd’，则可以执行命令。</p><figure class="highlight crmsh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl label nodes kubernetes-foo-<span class="keyword">node</span><span class="title">-1</span>.c.a-robinson.internal <span class="attr">disktype=</span>ssd</span><br></pre></td></tr></table></figure><p>你可以通过重新运行 kubectl get nodes —show-labels，查看节点当前具有了所指定的标签来验证它是否有效。 你也可以使用 命令查看指定节点的标签完整列表</p><figure class="highlight angelscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">[<span class="symbol">root@</span>VM_0_13_centos prometheus]# kubectl <span class="keyword">get</span> nodes --show-labels | grep ssd</span><br><span class="line"><span class="number">10.168</span><span class="number">.1</span><span class="number">.4</span>      Ready    &lt;none&gt;   <span class="number">48</span>d   v1<span class="number">.16</span><span class="number">.3</span>-tke<span class="number">.10</span>   beta.kubernetes.io/arch=amd64,beta.kubernetes.io/instance-type=QCLOUD,beta.kubernetes.io/os=linux,cloud.tencent.com/node-instance-id=ins<span class="number">-4</span>qz8yvgq,disktype=ssd,failure-domain.beta.kubernetes.io/region=gz,failure-domain.beta.kubernetes.io/zone=<span class="number">100003</span>,kubernetes.io/arch=amd64,kubernetes.io/hostname=<span class="number">10.168</span><span class="number">.1</span><span class="number">.4</span>,kubernetes.io/os=linux</span><br><span class="line">[<span class="symbol">root@</span>VM_0_13_centos prometheus]# kubectl describe node <span class="number">10.168</span><span class="number">.1</span><span class="number">.4</span></span><br><span class="line">Name:               <span class="number">10.168</span><span class="number">.1</span><span class="number">.4</span></span><br><span class="line">Roles:              &lt;none&gt;</span><br><span class="line">Labels:             beta.kubernetes.io/arch=amd64</span><br><span class="line">                    beta.kubernetes.io/instance-type=QCLOUD</span><br><span class="line">                    beta.kubernetes.io/os=linux</span><br><span class="line">                    cloud.tencent.com/node-instance-id=ins<span class="number">-4</span>qz8yvgq</span><br><span class="line">                    disktype=ssd</span><br><span class="line">                    failure-domain.beta.kubernetes.io/region=gz</span><br><span class="line">                    failure-domain.beta.kubernetes.io/zone=<span class="number">100003</span></span><br><span class="line">                    kubernetes.io/arch=amd64</span><br><span class="line">                    kubernetes.io/hostname=<span class="number">10.168</span><span class="number">.1</span><span class="number">.4</span></span><br><span class="line">                    kubernetes.io/os=linux</span><br></pre></td></tr></table></figure><h2 id="添加-nodeSelector-字段到-Pod-配置中"><a href="#添加-nodeSelector-字段到-Pod-配置中" class="headerlink" title="添加 nodeSelector 字段到 Pod 配置中"></a>添加 nodeSelector 字段到 Pod 配置中</h2><p>选择任何一个你想运行的 Pod 的配置文件，并且在其中添加一个 nodeSelector 部分。 例如，如果下面是我的 pod 配置</p><figure class="highlight less"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">apiVersion</span>: v1</span><br><span class="line"><span class="attribute">kind</span>: Pod</span><br><span class="line"><span class="attribute">metadata</span>:</span><br><span class="line">  <span class="attribute">name</span>: nginx</span><br><span class="line">  <span class="attribute">labels</span>:</span><br><span class="line">    <span class="attribute">env</span>: test</span><br><span class="line"><span class="attribute">spec</span>:</span><br><span class="line">  <span class="attribute">containers</span>:</span><br><span class="line">  - <span class="attribute">name</span>: nginx</span><br><span class="line">    <span class="attribute">image</span>: nginx</span><br><span class="line">    <span class="attribute">imagePullPolicy</span>: IfNotPresent</span><br><span class="line">  <span class="attribute">nodeSelector</span>:</span><br><span class="line">    <span class="attribute">disktype</span>: ssd</span><br></pre></td></tr></table></figure><p>执行上述yaml可以发现pod已经到到对应的ssd节点了</p><p><img src="1.png" alt="upload-image"></p><h2 id="k8s默认给节点打的标签"><a href="#k8s默认给节点打的标签" class="headerlink" title="k8s默认给节点打的标签"></a>k8s默认给节点打的标签</h2><figure class="highlight lua"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">kubernetes.<span class="built_in">io</span>/hostname</span><br><span class="line">failure-domain.beta.kubernetes.<span class="built_in">io</span>/zone</span><br><span class="line">failure-domain.beta.kubernetes.<span class="built_in">io</span>/region</span><br><span class="line">topology.kubernetes.<span class="built_in">io</span>/zone</span><br><span class="line">topology.kubernetes.<span class="built_in">io</span>/region</span><br><span class="line">beta.kubernetes.<span class="built_in">io</span>/instance-<span class="built_in">type</span></span><br><span class="line">node.kubernetes.<span class="built_in">io</span>/instance-<span class="built_in">type</span></span><br><span class="line">kubernetes.<span class="built_in">io</span>/<span class="built_in">os</span></span><br><span class="line">kubernetes.<span class="built_in">io</span>/arch</span><br></pre></td></tr></table></figure><h1 id="节点的亲和性和反亲和性"><a href="#节点的亲和性和反亲和性" class="headerlink" title="节点的亲和性和反亲和性"></a>节点的亲和性和反亲和性</h1><p>nodeSelector 提供了一种非常简单的方法来将 pod 约束到具有特定标签的节点上。亲和/反亲和功能极大地扩展了你可以表达约束的类型。关键的增强点是</p><ul><li>语言更具表现力（不仅仅是“完全匹配的 AND”）</li><li>你可以发现规则是“软”/“偏好”，而不是硬性要求，因此，如果调度器无法满足该要求，仍然调度该 pod</li><li>你可以使用节点上（或其他拓扑域中）的 pod 的标签来约束，而不是使用节点本身的标签，来允许哪些 pod 可以或者不可以被放置在一起。</li></ul><p>亲和功能包含两种类型的亲和，即“节点亲和”和“pod 间亲和/反亲和”。节点亲和就像现有的 nodeSelector（但具有上面列出的前两个好处），然而 pod 间亲和/反亲和约束 pod 标签而不是节点标签（在上面列出的第三项中描述，除了具有上面列出的第一和第二属性）</p><p>亲和性调度可以分成软策略和硬策略两种方式:</p><ul><li>软策略就是如果你没有满足调度要求的节点的话，pod 就会忽略这条规则，继续完成调度过程，说白了就是满足条件最好了，没有的话也无所谓了的策略</li><li>硬策略就比较强硬了，如果没有满足条件的节点的话，就不断重试直到满足条件为止，简单说就是你必须满足我的要求，不然我就不干的策略。</li></ul><p>对于亲和性和反亲和性都有这两种规则可以设置： preferredDuringSchedulingIgnoredDuringExecution和requiredDuringSchedulingIgnoredDuringExecution，前面的就是软策略，后面的就是硬策略。</p><p>目前有两种类型的节点亲和，分别为 requiredDuringSchedulingIgnoredDuringExecution 和 preferredDuringSchedulingIgnoredDuringExecution。你可以视它们为“硬”和“软”，意思是，前者指定了将 pod 调度到一个节点上必须满足的规则（就像 nodeSelector 但使用更具表现力的语法），后者指定调度器将尝试执行但不能保证的偏好。名称的“IgnoredDuringExecution”部分意味着，类似于 nodeSelector 的工作原理，如果节点的标签在运行时发生变更，从而不再满足 pod 上的亲和规则，那么 pod 将仍然继续在该节点上运行。</p><figure class="highlight less"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">apiVersion</span>: v1</span><br><span class="line"><span class="attribute">kind</span>: Pod</span><br><span class="line"><span class="attribute">metadata</span>:</span><br><span class="line">  <span class="attribute">name</span>: with-node-affinity</span><br><span class="line"><span class="attribute">spec</span>:</span><br><span class="line">  <span class="attribute">affinity</span>:</span><br><span class="line">    <span class="attribute">nodeAffinity</span>:</span><br><span class="line">      <span class="attribute">requiredDuringSchedulingIgnoredDuringExecution</span>:</span><br><span class="line">        <span class="attribute">nodeSelectorTerms</span>:</span><br><span class="line">        - <span class="attribute">matchExpressions</span>:</span><br><span class="line">          - <span class="attribute">key</span>: kubernetes.io/e2e-az-name</span><br><span class="line">            <span class="attribute">operator</span>: In</span><br><span class="line">            <span class="attribute">values</span>:</span><br><span class="line">            - e2e-az1</span><br><span class="line">            - e2e-az2</span><br><span class="line">      <span class="attribute">preferredDuringSchedulingIgnoredDuringExecution</span>:</span><br><span class="line">      - <span class="attribute">weight</span>: <span class="number">1</span></span><br><span class="line">        <span class="attribute">preference</span>:</span><br><span class="line">          <span class="attribute">matchExpressions</span>:</span><br><span class="line">          - <span class="attribute">key</span>: another-node-label-key</span><br><span class="line">            <span class="attribute">operator</span>: In</span><br><span class="line">            <span class="attribute">values</span>:</span><br><span class="line">            - another-node-label-value</span><br><span class="line">  <span class="attribute">containers</span>:</span><br><span class="line">  - <span class="attribute">name</span>: with-node-affinity</span><br><span class="line">    <span class="attribute">image</span>: k8s.gcr.io/<span class="attribute">pause</span>:<span class="number">2.0</span></span><br></pre></td></tr></table></figure><p>此节点亲和规则表示，pod 只能放置在具有标签键为 kubernetes.io/e2e-az-name 且 标签值为 e2e-az1 或 e2e-az2 的节点上。另外，在满足这些标准的节点中，具有标签键为 another-node-label-key 且标签值为 another-node-label-value 的节点应该优先使用。这里的匹配逻辑是 label 的值在某个列表中，现在Kubernetes提供的操作符有下面的几种：</p><ul><li>In：label 的值在某个列表中</li><li>NotIn：label 的值不在某个列表中</li><li>Gt：label 的值大于某个值</li><li>Lt：label 的值小于某个值</li><li>Exists：某个 label 存在</li><li>DoesNotExist：某个 label 不存在</li></ul><p>如果nodeSelectorTerms下面有多个选项的话，满足任何一个条件就可以了；如果matchExpressions有多个选项的话，则必须同时满足这些条件才能正常调度 POD。</p><p>preferredDuringSchedulingIgnoredDuringExecution 中的 weight 字段值的范围是 1-100。对于每个符合所有调度要求（资源请求，RequiredDuringScheduling 亲和表达式等）的节点，调度器将遍历该字段的元素来计算总和，并且如果节点匹配对应的MatchExpressions，则添加“权重”到总和。然后将这个评分与该节点的其他优先级函数的评分进行组合。总分最高的节点是最优选</p><h1 id="pod的亲和性和反亲和性"><a href="#pod的亲和性和反亲和性" class="headerlink" title="pod的亲和性和反亲和性"></a>pod的亲和性和反亲和性</h1><p>pod 间亲和与反亲和使你可以基于已经在节点上运行的 pod 的标签来约束 pod 可以调度到的节点，而不是基于节点上的标签。规则的格式为“如果 X 节点上已经运行了一个或多个 满足规则 Y 的pod，则这个 pod 应该（或者在非亲和的情况下不应该）运行在 X 节点”。Y 表示一个具有可选的关联命令空间列表的 LabelSelector；与节点不同，因为 pod 是命名空间限定的（因此 pod 上的标签也是命名空间限定的），因此作用于 pod 标签的标签选择器必须指定选择器应用在哪个命名空间。从概念上讲，X 是一个拓扑域，如节点，机架，云供应商地区，云供应商区域等。你可以使用 topologyKey 来表示它，topologyKey 是节点标签的键以便系统用来表示这样的拓扑域。这里拓扑域可以从默认的标签中选择</p><p>pod 亲和性主要解决 pod 可以和哪些 pod 部署在同一个拓扑域中的问题（其中拓扑域用主机标签实现，可以是单个主机，也可以是多个主机组成的 cluster、zone 等等），而 pod 反亲和性主要是解决 pod 不能和哪些 pod 部署在同一个拓扑域中的问题，它们都是处理的 pod 与 pod 之间的关系，比如一个 pod 在一个节点上了，那么我这个也得在这个节点，或者你这个 pod 在节点上了，那么我就不想和你待在同一个节点上。</p><p>由于我们这里只有一个集群，并没有区域或者机房的概念，所以我们这里直接使用主机名来作为拓扑域，把 pod 创建在同一个主机上面。</p><figure class="highlight angelscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[<span class="symbol">root@</span>VM_0_13_centos prometheus]# kubectl <span class="keyword">get</span> nodes --show-labels</span><br><span class="line">NAME            STATUS   ROLES    AGE   VERSION          LABELS</span><br><span class="line"><span class="number">10.168</span><span class="number">.1</span><span class="number">.4</span>      Ready    &lt;none&gt;   <span class="number">48</span>d   v1<span class="number">.16</span><span class="number">.3</span>-tke<span class="number">.10</span>   beta.kubernetes.io/arch=amd64,beta.kubernetes.io/instance-type=QCLOUD,beta.kubernetes.io/os=linux,cloud.tencent.com/node-instance-id=ins<span class="number">-4</span>qz8yvgq,disktype=ssd,failure-domain.beta.kubernetes.io/region=gz,failure-domain.beta.kubernetes.io/zone=<span class="number">100003</span>,kubernetes.io/arch=amd64,kubernetes.io/hostname=<span class="number">10.168</span><span class="number">.1</span><span class="number">.4</span>,kubernetes.io/os=linux</span><br><span class="line"><span class="number">10.168</span><span class="number">.1</span><span class="number">.5</span>      Ready    &lt;none&gt;   <span class="number">17</span>d   v1<span class="number">.16</span><span class="number">.3</span>-tke<span class="number">.10</span>   beta.kubernetes.io/arch=amd64,beta.kubernetes.io/instance-type=QCLOUD,beta.kubernetes.io/os=linux,cloud.tencent.com/node-instance-id=ins-ft3pcr72,failure-domain.beta.kubernetes.io/region=gz,failure-domain.beta.kubernetes.io/zone=<span class="number">100003</span>,kubernetes.io/arch=amd64,kubernetes.io/hostname=<span class="number">10.168</span><span class="number">.1</span><span class="number">.5</span>,kubernetes.io/os=linux</span><br><span class="line"><span class="number">10.168</span><span class="number">.100</span><span class="number">.22</span>   Ready    &lt;none&gt;   <span class="number">18</span>d   v1<span class="number">.16</span><span class="number">.3</span>-tke<span class="number">.10</span>   beta.kubernetes.io/arch=amd64,beta.kubernetes.io/instance-type=QCLOUD,beta.kubernetes.io/os=linux,cloud.tencent.com/node-instance-id=ins-iomm694e,failure-domain.beta.kubernetes.io/region=gz,failure-domain.beta.kubernetes.io/zone=<span class="number">100003</span>,kubernetes.io/arch=amd64,kubernetes.io/hostname=<span class="number">10.168</span><span class="number">.100</span><span class="number">.22</span>,kubernetes.io/os=linux</span><br></pre></td></tr></table></figure><p>与节点亲和一样，当前有两种类型的 pod 亲和与反亲和，即 requiredDuringSchedulingIgnoredDuringExecution 和 preferredDuringSchedulingIgnoredDuringExecution，分表表示“硬性”与“软性”要求。请参阅前面节点亲和部分中的描述。requiredDuringSchedulingIgnoredDuringExecution 亲和的一个示例是“将服务 A 和服务 B 的 pod 放置在同一区域，因为它们之间进行大量交流”，而 preferredDuringSchedulingIgnoredDuringExecution 反亲和的示例将是“将此服务的 pod 跨区域分布”（硬性要求是说不通的，因为你可能拥有的 pod 数多于区域数）。</p><p>Pod 间亲和通过 PodSpec 中 affinity 字段下的 podAffinity 字段进行指定。而 pod 间反亲和通过 PodSpec 中 affinity 字段下的 podAntiAffinity 字段进行指定</p><figure class="highlight less"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">apiVersion</span>: v1</span><br><span class="line"><span class="attribute">kind</span>: Pod</span><br><span class="line"><span class="attribute">metadata</span>:</span><br><span class="line">  <span class="attribute">name</span>: with-pod-affinity</span><br><span class="line"><span class="attribute">spec</span>:</span><br><span class="line">  <span class="attribute">affinity</span>:</span><br><span class="line">    <span class="attribute">podAffinity</span>:</span><br><span class="line">      <span class="attribute">requiredDuringSchedulingIgnoredDuringExecution</span>:</span><br><span class="line">      - <span class="attribute">labelSelector</span>:</span><br><span class="line">          <span class="attribute">matchExpressions</span>:</span><br><span class="line">          - <span class="attribute">key</span>: security</span><br><span class="line">            <span class="attribute">operator</span>: In</span><br><span class="line">            <span class="attribute">values</span>:</span><br><span class="line">            - S1</span><br><span class="line">        <span class="attribute">topologyKey</span>: failure-domain.beta.kubernetes.io/zone</span><br><span class="line">    <span class="attribute">podAntiAffinity</span>:</span><br><span class="line">      <span class="attribute">preferredDuringSchedulingIgnoredDuringExecution</span>:</span><br><span class="line">      - <span class="attribute">weight</span>: <span class="number">100</span></span><br><span class="line">        <span class="attribute">podAffinityTerm</span>:</span><br><span class="line">          <span class="attribute">labelSelector</span>:</span><br><span class="line">            <span class="attribute">matchExpressions</span>:</span><br><span class="line">            - <span class="attribute">key</span>: security</span><br><span class="line">              <span class="attribute">operator</span>: In</span><br><span class="line">              <span class="attribute">values</span>:</span><br><span class="line">              - S2</span><br><span class="line">          <span class="attribute">topologyKey</span>: failure-domain.beta.kubernetes.io/zone</span><br><span class="line">  <span class="attribute">containers</span>:</span><br><span class="line">  - <span class="attribute">name</span>: with-pod-affinity</span><br><span class="line">    <span class="attribute">image</span>: k8s.gcr.io/<span class="attribute">pause</span>:<span class="number">2.0</span></span><br></pre></td></tr></table></figure><h2 id="podAffinity"><a href="#podAffinity" class="headerlink" title="podAffinity"></a>podAffinity</h2><p>下面我来实践下pod的亲和性，下面这个例子中的 pod 需要调度到某个指定的主机上，至少有一个节点上运行了这样的 pod：这个 pod 有一个app=redis的 label。</p><figure class="highlight angelscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[<span class="symbol">root@</span>VM_0_13_centos ~]# kubectl <span class="keyword">get</span> pod --show-labels -o wide | grep app=redis</span><br><span class="line">redis<span class="number">-866f</span>79579<span class="number">-2</span>qdfp                  <span class="number">1</span>/<span class="number">1</span>     Running   <span class="number">0</span>          <span class="number">16</span>d   <span class="number">172.16</span><span class="number">.3</span><span class="number">.79</span>    <span class="number">10.168</span><span class="number">.1</span><span class="number">.4</span>      &lt;none&gt;           &lt;none&gt;            app=redis,pod-template-hash=<span class="number">866f</span>79579</span><br></pre></td></tr></table></figure><p>测试pod亲和性的yaml文件</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">apps/v1beta1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Deployment</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">affinity</span></span><br><span class="line">  <span class="attr">labels:</span></span><br><span class="line">    <span class="attr">app:</span> <span class="string">affinity</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">replicas:</span> <span class="number">3</span></span><br><span class="line">  <span class="attr">revisionHistoryLimit:</span> <span class="number">15</span></span><br><span class="line">  <span class="attr">template:</span></span><br><span class="line">    <span class="attr">metadata:</span></span><br><span class="line">      <span class="attr">labels:</span></span><br><span class="line">        <span class="attr">app:</span> <span class="string">affinity</span></span><br><span class="line">        <span class="attr">role:</span> <span class="string">test</span></span><br><span class="line">    <span class="attr">spec:</span></span><br><span class="line">      <span class="attr">containers:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">nginx</span></span><br><span class="line">        <span class="attr">image:</span> <span class="string">nginx:1.7.9</span></span><br><span class="line">        <span class="attr">ports:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">containerPort:</span> <span class="number">80</span></span><br><span class="line">          <span class="attr">name:</span> <span class="string">nginxweb</span></span><br><span class="line">      <span class="attr">affinity:</span></span><br><span class="line">        <span class="attr">podAffinity:</span></span><br><span class="line">          <span class="attr">requiredDuringSchedulingIgnoredDuringExecution:</span>  <span class="comment"># 硬策略</span></span><br><span class="line">          <span class="bullet">-</span> <span class="attr">labelSelector:</span></span><br><span class="line">              <span class="attr">matchExpressions:</span></span><br><span class="line">              <span class="bullet">-</span> <span class="attr">key:</span> <span class="string">app</span></span><br><span class="line">                <span class="attr">operator:</span> <span class="string">In</span></span><br><span class="line">                <span class="attr">values:</span></span><br><span class="line">                <span class="bullet">-</span> <span class="string">redis</span></span><br><span class="line">            <span class="attr">topologyKey:</span> <span class="string">kubernetes.io/hostname</span></span><br></pre></td></tr></table></figure><p>我们看到这个 pod 运行在了10.168.1.4的节点上面，所以按照上面的亲和性来说，上面我们部署的3个 pod 副本也应该运行在 10.168.1.4节点上：</p><figure class="highlight angelscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[<span class="symbol">root@</span>VM_0_13_centos ~]# kubectl <span class="keyword">get</span> pod -o wide | grep affinity</span><br><span class="line">affinity<span class="number">-547</span>c75bd94-hkx47              <span class="number">1</span>/<span class="number">1</span>     Running   <span class="number">0</span>          <span class="number">19</span>s   <span class="number">172.16</span><span class="number">.3</span><span class="number">.91</span>    <span class="number">10.168</span><span class="number">.1</span><span class="number">.4</span>      &lt;none&gt;           &lt;none&gt;</span><br><span class="line">affinity<span class="number">-547</span>c75bd94-tg22d              <span class="number">1</span>/<span class="number">1</span>     Running   <span class="number">0</span>          <span class="number">19</span>s   <span class="number">172.16</span><span class="number">.3</span><span class="number">.89</span>    <span class="number">10.168</span><span class="number">.1</span><span class="number">.4</span>      &lt;none&gt;           &lt;none&gt;</span><br><span class="line">affinity<span class="number">-547</span>c75bd94-vfm7f              <span class="number">1</span>/<span class="number">1</span>     Running   <span class="number">0</span>          <span class="number">19</span>s   <span class="number">172.16</span><span class="number">.3</span><span class="number">.90</span>    <span class="number">10.168</span><span class="number">.1</span><span class="number">.4</span>      &lt;none&gt;           &lt;none&gt;</span><br></pre></td></tr></table></figure><p>下面我们把redis的标签改下，然后重建下deloyment看下，看下会发生什么情况</p><figure class="highlight angelscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[<span class="symbol">root@</span>VM_0_13_centos ~]# kubectl <span class="keyword">get</span> pod --show-labels -o wide | grep app=redis</span><br><span class="line">redis<span class="number">-5</span>b4495ddb4-szjtz                 <span class="number">1</span>/<span class="number">1</span>     Running   <span class="number">0</span>          <span class="number">18</span>s     <span class="number">172.16</span><span class="number">.3</span><span class="number">.92</span>    <span class="number">10.168</span><span class="number">.1</span><span class="number">.4</span>      &lt;none&gt;           &lt;none&gt;            k8s-app=redis,pod-template-hash=<span class="number">5</span>b4495ddb4,qcloud-app=redis</span><br></pre></td></tr></table></figure><figure class="highlight angelscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[<span class="symbol">root@</span>VM_0_13_centos ~]# kubectl <span class="keyword">get</span> pod </span><br><span class="line">NAME                                   READY   STATUS    RESTARTS   AGE</span><br><span class="line">affinity<span class="number">-547</span>c75bd94<span class="number">-8</span>jcb8              <span class="number">0</span>/<span class="number">1</span>     Pending   <span class="number">0</span>          <span class="number">11</span>s</span><br><span class="line">affinity<span class="number">-547</span>c75bd94<span class="number">-9</span>wv9d              <span class="number">0</span>/<span class="number">1</span>     Pending   <span class="number">0</span>          <span class="number">10</span>s</span><br><span class="line">affinity<span class="number">-547</span>c75bd94-bq8qh              <span class="number">0</span>/<span class="number">1</span>     Pending   <span class="number">0</span>          <span class="number">10</span>s</span><br></pre></td></tr></table></figure><p>我们可以看到处于Pending状态了，这是因为现在没有一个节点上面拥有busybox-pod这个 label 的 pod，而上面我们的调度使用的是硬策略，所以就没办法进行调度了</p><p>我们这个地方使用的是kubernetes.io/hostname这个拓扑域，意思就是我们当前调度的 pod 要和目标的 pod 处于同一个主机上面，因为要处于同一个拓扑域下面，为了说明这个问题，我们把拓扑域改成beta.kubernetes.io/os，同样的我们当前调度的 pod 要和目标的 pod 处于同一个拓扑域中，目标的 pod 是不是拥有beta.kubernetes.io/os=linux的标签，而我们这里3个节点都有这样的标签，这也就意味着我们3个节点都在同一个拓扑域中，所以我们这里的 pod 可能会被调度到任何一个节点：</p><figure class="highlight less"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">spec</span>:</span><br><span class="line">  <span class="attribute">affinity</span>:</span><br><span class="line">    <span class="attribute">podAffinity</span>:</span><br><span class="line">      <span class="attribute">requiredDuringSchedulingIgnoredDuringExecution</span>:</span><br><span class="line">      - <span class="attribute">labelSelector</span>:</span><br><span class="line">          <span class="attribute">matchExpressions</span>:</span><br><span class="line">          - <span class="attribute">key</span>: k8s-app</span><br><span class="line">            <span class="attribute">operator</span>: In</span><br><span class="line">            <span class="attribute">values</span>:</span><br><span class="line">            - redis</span><br><span class="line">        <span class="attribute">topologyKey</span>: beta.kubernetes.io/os</span><br></pre></td></tr></table></figure><figure class="highlight angelscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[<span class="symbol">root@</span>VM_0_13_centos ~]# kubectl <span class="keyword">get</span> pod -o wide | grep affinity</span><br><span class="line">affinity<span class="number">-87649f</span>558<span class="number">-6</span>p72d               <span class="number">1</span>/<span class="number">1</span>     Running   <span class="number">0</span>          <span class="number">3</span>m22s   <span class="number">172.16</span><span class="number">.2</span><span class="number">.160</span>   <span class="number">10.168</span><span class="number">.1</span><span class="number">.5</span>      &lt;none&gt;           &lt;none&gt;</span><br><span class="line">affinity<span class="number">-87649f</span>558-fpcxg               <span class="number">1</span>/<span class="number">1</span>     Running   <span class="number">0</span>          <span class="number">3</span>m22s   <span class="number">172.16</span><span class="number">.3</span><span class="number">.94</span>    <span class="number">10.168</span><span class="number">.1</span><span class="number">.4</span>      &lt;none&gt;           &lt;none&gt;</span><br><span class="line">affinity<span class="number">-87649f</span>558-h8scw               <span class="number">1</span>/<span class="number">1</span>     Running   <span class="number">0</span>          <span class="number">2</span>m22s   <span class="number">172.16</span><span class="number">.2</span><span class="number">.126</span>   <span class="number">10.168</span><span class="number">.100</span><span class="number">.22</span>   &lt;none&gt;           &lt;none&gt;</span><br></pre></td></tr></table></figure><h2 id="podAntiAffinity"><a href="#podAntiAffinity" class="headerlink" title="podAntiAffinity"></a>podAntiAffinity</h2><p>这就是 pod 亲和性的用法，而 pod 反亲和性则是反着来的，比如一个节点上运行了某个 pod，那么我们的 pod 则希望被调度到其他节点上去，同样我们把上面的 podAffinity 直接改成 podAntiAffinity，(pod-antiaffinity-demo.yaml)</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">apps/v1beta1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Deployment</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">affinity</span></span><br><span class="line">  <span class="attr">labels:</span></span><br><span class="line">    <span class="attr">app:</span> <span class="string">affinity</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">replicas:</span> <span class="number">3</span></span><br><span class="line">  <span class="attr">revisionHistoryLimit:</span> <span class="number">15</span></span><br><span class="line">  <span class="attr">template:</span></span><br><span class="line">    <span class="attr">metadata:</span></span><br><span class="line">      <span class="attr">labels:</span></span><br><span class="line">        <span class="attr">app:</span> <span class="string">affinity</span></span><br><span class="line">        <span class="attr">role:</span> <span class="string">test</span></span><br><span class="line">    <span class="attr">spec:</span></span><br><span class="line">      <span class="attr">containers:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">nginx</span></span><br><span class="line">        <span class="attr">image:</span> <span class="string">nginx:1.7.9</span></span><br><span class="line">        <span class="attr">ports:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">containerPort:</span> <span class="number">80</span></span><br><span class="line">          <span class="attr">name:</span> <span class="string">nginxweb</span></span><br><span class="line">      <span class="attr">affinity:</span></span><br><span class="line">        <span class="attr">podAntiAffinity:</span></span><br><span class="line">          <span class="attr">requiredDuringSchedulingIgnoredDuringExecution:</span>  <span class="comment"># 硬策略</span></span><br><span class="line">          <span class="bullet">-</span> <span class="attr">labelSelector:</span></span><br><span class="line">              <span class="attr">matchExpressions:</span></span><br><span class="line">              <span class="bullet">-</span> <span class="attr">key:</span> <span class="string">k8s-app</span></span><br><span class="line">                <span class="attr">operator:</span> <span class="string">In</span></span><br><span class="line">                <span class="attr">values:</span></span><br><span class="line">                <span class="bullet">-</span> <span class="string">redis</span></span><br><span class="line">            <span class="attr">topologyKey:</span> <span class="string">kubernetes.io/hostname</span></span><br></pre></td></tr></table></figure><p>这里的意思就是如果一个节点上面有一个k8s-app=redis这样的 pod 的话，那么我们的 pod 就别调度到这个节点上面来，上面我们k8s-app=redis在10.168.1.4这个节点上，正常来说我们这里的 pod 不会出现在 10.168.1.4节点上</p><figure class="highlight angelscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[<span class="symbol">root@</span>VM_0_13_centos ~]# kubectl <span class="keyword">get</span> pod -o wide | grep redis</span><br><span class="line">redis<span class="number">-5</span>b4495ddb4-szjtz                 <span class="number">1</span>/<span class="number">1</span>     Running   <span class="number">0</span>          <span class="number">23</span>m     <span class="number">172.16</span><span class="number">.3</span><span class="number">.92</span>    <span class="number">10.168</span><span class="number">.1</span><span class="number">.4</span>      &lt;none&gt;           &lt;none&gt;</span><br><span class="line">[<span class="symbol">root@</span>VM_0_13_centos ~]# kubectl <span class="keyword">get</span> pod -o wide | grep affinity</span><br><span class="line">affinity<span class="number">-6868874</span>dbc<span class="number">-5</span>cc95              <span class="number">1</span>/<span class="number">1</span>     Running   <span class="number">0</span>          <span class="number">2</span>m26s   <span class="number">172.16</span><span class="number">.2</span><span class="number">.68</span>    <span class="number">10.168</span><span class="number">.100</span><span class="number">.22</span>   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">affinity<span class="number">-6868874</span>dbc-g6vb2              <span class="number">1</span>/<span class="number">1</span>     Running   <span class="number">0</span>          <span class="number">2</span>m28s   <span class="number">172.16</span><span class="number">.2</span><span class="number">.162</span>   <span class="number">10.168</span><span class="number">.1</span><span class="number">.5</span>      &lt;none&gt;           &lt;none&gt;</span><br><span class="line">affinity<span class="number">-6868874</span>dbc-zbpt4              <span class="number">1</span>/<span class="number">1</span>     Running   <span class="number">0</span>          <span class="number">2</span>m30s   <span class="number">172.16</span><span class="number">.2</span><span class="number">.67</span>    <span class="number">10.168</span><span class="number">.100</span><span class="number">.22</span>   &lt;none&gt;           &lt;none&gt;</span><br></pre></td></tr></table></figure><h1 id="污点和容忍"><a href="#污点和容忍" class="headerlink" title="污点和容忍"></a>污点和容忍</h1><p>污点和容忍度（Toleration）相互配合，可以用来避免 Pod 被分配到不合适的节点上。 每个节点上都可以应用一个或多个污点，这表示对于那些不能容忍这些污点的 Pod，是不会被该节点接受的</p><p>对于nodeAffinity无论是硬策略还是软策略方式，都是调度 pod 到预期节点上，而Taints恰好与之相反，如果一个节点标记为 Taints ，除非 pod 也被标识为可以容忍污点节点，否则该 Taints 节点不会被调度 pod。</p><p>比如我们的Master 节点保留给 Kubernetes 系统组件使用，或者把一组具有特殊资源预留给某些 pod，则污点就很有用了，pod 不会再被调度到 taint 标记过的节点。我们使用kubeadm搭建的集群默认就给 master 节点添加了一个污点标记，所以我们看到我们平时的 pod 都没有被调度到 master 上</p><figure class="highlight crmsh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">[tke@VM_0_13_centos ~]$ kubectl describe <span class="keyword">node</span> <span class="title">192</span>.<span class="number">168.100</span>.<span class="number">11</span></span><br><span class="line">Name:               <span class="number">192.168</span>.<span class="number">100.11</span></span><br><span class="line">Roles:              <span class="literal">master</span></span><br><span class="line">Labels:             beta.kubernetes.io/<span class="attr">arch=</span>amd64</span><br><span class="line">                    beta.kubernetes.io/<span class="attr">instance-type=</span>QCLOUD</span><br><span class="line">                    beta.kubernetes.io/<span class="attr">os=</span>linux</span><br><span class="line">                    cloud.tencent.com/<span class="keyword">node</span><span class="title">-instance-id</span>=ins-<span class="number">1</span>zeb156t</span><br><span class="line">                    failure-domain.beta.kubernetes.io/<span class="attr">region=</span>cd</span><br><span class="line">                    failure-domain.beta.kubernetes.io/<span class="attr">zone=</span><span class="number">160001</span></span><br><span class="line">                    kubernetes.io/<span class="attr">arch=</span>amd64</span><br><span class="line">                    kubernetes.io/<span class="attr">hostname=</span><span class="number">192.168</span>.<span class="number">100.11</span></span><br><span class="line">                    kubernetes.io/<span class="keyword">node</span><span class="title">-role-etcd</span>=<span class="literal">true</span></span><br><span class="line">                    kubernetes.io/<span class="attr">os=</span>linux</span><br><span class="line">                    <span class="keyword">node</span><span class="title">-role</span>.kubernetes.io/<span class="attr">master=</span><span class="literal">true</span></span><br><span class="line">Annotations:        <span class="keyword">node</span>.<span class="title">alpha</span>.kubernetes.io/ttl: <span class="number">0</span></span><br><span class="line">                    volumes.kubernetes.io/controller-managed-attach-detach: <span class="literal">true</span></span><br><span class="line">CreationTimestamp:  Wed, <span class="number">17</span> Jun <span class="number">2020</span> <span class="number">10</span>:<span class="number">51</span>:<span class="number">00</span> +<span class="number">0800</span></span><br><span class="line">Taints:             <span class="keyword">node</span><span class="title">-role</span>.kubernetes.io/<span class="literal">master</span>:NoSchedule</span><br></pre></td></tr></table></figure><p>我们可以使用上面的命令查看 master 节点的信息，其中有一条关于 Taints 的信息：node-role.kubernetes.io/master:NoSchedule，就表示给 master 节点打了一个污点的标记，其中影响的参数是NoSchedule，表示 pod 不会被调度到标记为 taints 的节点，除了 NoSchedule 外，还有另外两个选项：</p><ul><li>PreferNoSchedule：NoSchedule 的软策略版本，表示尽量不调度到污点节点上去</li><li>NoExecute：该选项意味着一旦 Taint 生效，如该节点内正在运行的 pod 没有对应 Tolerate 设置，会直接被逐出</li></ul><h2 id="节点添加和去除污点"><a href="#节点添加和去除污点" class="headerlink" title="节点添加和去除污点"></a>节点添加和去除污点</h2><p>您可以使用命令 kubectl taint 给节点增加一个污点。比如，</p><figure class="highlight q"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl taint nodes node1 <span class="built_in">key</span>=<span class="built_in">value</span>:NoSchedule</span><br></pre></td></tr></table></figure><p>给节点 node1 增加一个污点，它的键名是 key，键值是 value，效果是 NoSchedule。 这表示只有拥有和这个污点相匹配的容忍度的 Pod 才能够被分配到 node1 这个节点。</p><figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="selector-tag">kubectl</span> <span class="selector-tag">taint</span> <span class="selector-tag">nodes</span> <span class="selector-tag">node1</span> <span class="selector-tag">key</span><span class="selector-pseudo">:NoSchedule-</span></span><br></pre></td></tr></table></figure><p>若要移除上述命令所添加的污点，你可以执行：</p><figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="selector-tag">kubectl</span> <span class="selector-tag">taint</span> <span class="selector-tag">nodes</span> <span class="selector-tag">node1</span> <span class="selector-tag">key</span><span class="selector-pseudo">:NoSchedule-</span></span><br></pre></td></tr></table></figure><h2 id="pod容忍污点"><a href="#pod容忍污点" class="headerlink" title="pod容忍污点"></a>pod容忍污点</h2><p>您可以在 PodSpec 中定义 Pod 的容忍度。 下面两个容忍度均与上面例子中使用 kubectl taint 命令创建的污点相匹配， 因此如果一个 Pod 拥有其中的任何一个容忍度都能够被分配到 node1 ：</p><figure class="highlight less"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">tolerations</span>:</span><br><span class="line">- <span class="attribute">key</span>: <span class="string">"key"</span></span><br><span class="line">  <span class="attribute">operator</span>: <span class="string">"Equal"</span></span><br><span class="line">  <span class="attribute">value</span>: <span class="string">"value"</span></span><br><span class="line">  <span class="attribute">effect</span>: <span class="string">"NoSchedule"</span></span><br><span class="line"><span class="attribute">tolerations</span>:</span><br><span class="line">- <span class="attribute">key</span>: <span class="string">"key"</span></span><br><span class="line">  <span class="attribute">operator</span>: <span class="string">"Exists"</span></span><br><span class="line">  <span class="attribute">effect</span>: <span class="string">"NoSchedule"</span></span><br><span class="line">这里是一个使用了容忍度的 Pod：pods/pod-with-toleration.yaml </span><br><span class="line"><span class="attribute">apiVersion</span>: v1</span><br><span class="line"><span class="attribute">kind</span>: Pod</span><br><span class="line"><span class="attribute">metadata</span>:</span><br><span class="line">  <span class="attribute">name</span>: nginx</span><br><span class="line">  <span class="attribute">labels</span>:</span><br><span class="line">    <span class="attribute">env</span>: test</span><br><span class="line"><span class="attribute">spec</span>:</span><br><span class="line">  <span class="attribute">containers</span>:</span><br><span class="line">  - <span class="attribute">name</span>: nginx</span><br><span class="line">    <span class="attribute">image</span>: nginx</span><br><span class="line">    <span class="attribute">imagePullPolicy</span>: IfNotPresent</span><br><span class="line">  <span class="attribute">tolerations</span>:</span><br><span class="line">  - <span class="attribute">key</span>: <span class="string">"example-key"</span></span><br><span class="line">    <span class="attribute">operator</span>: <span class="string">"Exists"</span></span><br><span class="line">    <span class="attribute">effect</span>: <span class="string">"NoSchedule"</span></span><br></pre></td></tr></table></figure><p>对于 tolerations 属性的写法，其中的 key、value、effect 与 Node 的 Taint 设置需保持一致， 还有以下几点说明：</p><ol><li>如果 operator 的值是 Exists，则 value 属性可省略</li><li>如果 operator 的值是 Equal，则表示其 key 与 value 之间的关系是 equal(等于)</li><li>如果不指定 operator 属性，则默认值为 Equal</li></ol><p>另外，还有两个特殊值：</p><ol><li>空的 key 如果再配合 Exists 就能匹配所有的 key 与 value，也是是能容忍所有 node 的所有 Taints</li><li>空的 effect 匹配所有的 effect</li></ol><h2 id="多个污点的pod容忍策略"><a href="#多个污点的pod容忍策略" class="headerlink" title="多个污点的pod容忍策略"></a>多个污点的pod容忍策略</h2><p>您可以给一个节点添加多个污点，也可以给一个 Pod 添加多个容忍度设置。 Kubernetes 处理多个污点和容忍度的过程就像一个过滤器：从一个节点的所有污点开始遍历， 过滤掉那些 Pod 中存在与之相匹配的容忍度的污点。余下未被过滤的污点的 effect 值决定了 Pod 是否会被分配到该节点，特别是以下情况：</p><ul><li>如果未被过滤的污点中存在至少一个 effect 值为 NoSchedule 的污点， 则 Kubernetes 不会将 Pod 分配到该节点。</li><li>如果未被过滤的污点中不存在 effect 值为 NoSchedule 的污点， 但是存在 effect 值为 PreferNoSchedule 的污点， 则 Kubernetes 会 尝试 将 Pod 分配到该节点。</li><li>如果未被过滤的污点中存在至少一个 effect 值为 NoExecute 的污点， 则 Kubernetes 不会将 Pod 分配到该节点（如果 Pod 还未在节点上运行）， 或者将 Pod 从该节点驱逐（如果 Pod 已经在节点上运行）。</li></ul><h2 id="NoExecute类型pod继续运行时间"><a href="#NoExecute类型pod继续运行时间" class="headerlink" title="NoExecute类型pod继续运行时间"></a>NoExecute类型pod继续运行时间</h2><p>通常情况下，如果给一个节点添加了一个 effect 值为 NoExecute 的污点， 则任何不能忍受这个污点的 Pod 都会马上被驱逐， 任何可以忍受这个污点的 Pod 都不会被驱逐。 但是，如果 Pod 存在一个 effect 值为 NoExecute 的容忍度指定了可选属性 tolerationSeconds 的值，则表示在给节点添加了上述污点之后， Pod 还能继续在节点上运行的时间。例如，</p><figure class="highlight less"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">tolerations</span>:</span><br><span class="line">- <span class="attribute">key</span>: <span class="string">"key1"</span></span><br><span class="line">  <span class="attribute">operator</span>: <span class="string">"Equal"</span></span><br><span class="line">  <span class="attribute">value</span>: <span class="string">"value1"</span></span><br><span class="line">  <span class="attribute">effect</span>: <span class="string">"NoExecute"</span></span><br><span class="line">  <span class="attribute">tolerationSeconds</span>: <span class="number">3600</span></span><br></pre></td></tr></table></figure><p>这表示如果这个 Pod 正在运行，同时一个匹配的污点被添加到其所在的节点， 那么 Pod 还将继续在节点上运行 3600 秒，然后被驱逐。 如果在此之前上述污点被删除了，则 Pod 不会被驱逐。</p><h2 id="节点发生异常pod发生驱逐的原理"><a href="#节点发生异常pod发生驱逐的原理" class="headerlink" title="节点发生异常pod发生驱逐的原理"></a>节点发生异常pod发生驱逐的原理</h2><p>一般我们节点发生异常的时候，节点为什么会把pod驱逐走呢，其实这个背后的原理是污点起的作用，当节点出现了异常的情况的时候，控制器会给节点打上一些污点，由于这个节点上的pod没有容忍这些污点从而被驱逐。下面是节点不同异常状态下控制器给节点打的污点类型</p><figure class="highlight crmsh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">node</span>.<span class="title">kubernetes</span>.io/not-ready：节点未准备好。这相当于节点状态 Ready 的值为 <span class="string">"False"</span>。</span><br><span class="line"><span class="keyword">node</span>.<span class="title">kubernetes</span>.io/unreachable：节点控制器访问不到节点. 这相当于节点状态 Ready 的值为 <span class="string">"Unknown"</span>。</span><br><span class="line"><span class="keyword">node</span>.<span class="title">kubernetes</span>.io/out-of-disk：节点磁盘耗尽。</span><br><span class="line"><span class="keyword">node</span>.<span class="title">kubernetes</span>.io/memory-pressure：节点存在内存压力。</span><br><span class="line"><span class="keyword">node</span>.<span class="title">kubernetes</span>.io/disk-pressure：节点存在磁盘压力。</span><br><span class="line"><span class="keyword">node</span>.<span class="title">kubernetes</span>.io/network-unavailable：节点网络不可用。</span><br><span class="line"><span class="keyword">node</span>.<span class="title">kubernetes</span>.io/unschedulable: 节点不可调度。</span><br><span class="line"><span class="keyword">node</span>.<span class="title">cloudprovider</span>.kubernetes.io/uninitialized：如果 kubelet 启动时指定了一个 <span class="string">"外部"</span> 云平台驱动， 它将给当前节点添加一个污点将其标志为不可用。在 cloud-controller-manager 的一个控制器初始化这个节点后，kubelet 将删除这个污点。</span><br></pre></td></tr></table></figure><p>如果节点恢复了，节点控制器会删除给节点打上的污点，这样pod就可以调度到这些节点上了。</p><p>如果我希望节点发生异常后，pod不马上发生驱逐，想在节点上再运行一段时间，那么这里可以用tolerationSeconds参数来处理，比如，一个使用了很多本地状态的应用程序在网络断开时，仍然希望停留在当前节点上运行一段较长的时间， 愿意等待网络恢复以避免被驱逐。在这种情况下，Pod 的容忍度可能是下面这样的：</p><figure class="highlight less"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">tolerations</span>:</span><br><span class="line">- <span class="attribute">key</span>: <span class="string">"node.kubernetes.io/unreachable"</span></span><br><span class="line">  <span class="attribute">operator</span>: <span class="string">"Exists"</span></span><br><span class="line">  <span class="attribute">effect</span>: <span class="string">"NoExecute"</span></span><br><span class="line">  <span class="attribute">tolerationSeconds</span>: <span class="number">6000</span></span><br></pre></td></tr></table></figure><p>节点异常后k8s中控制器会为默认给pod加上tolerationSeconds=600这个参数，避免node发生异常pod立马被驱逐</p><p><strong>说明</strong>：Kubernetes 会自动给 Pod 添加一个 key 为 node.kubernetes.io/not-ready 的容忍度 并配置 tolerationSeconds=300，除非用户提供的 Pod 配置中已经已存在了 key 为 node.kubernetes.io/not-ready 的容忍度。</p><p><strong>同样</strong>，Kubernetes 会给 Pod 添加一个 key 为 node.kubernetes.io/unreachable 的容忍度 并配置 tolerationSeconds=300，除非用户提供的 Pod 配置中已经已存在了 key 为 node.kubernetes.io/unreachable 的容忍度。</p><h2 id="DaemonSet的调度和驱逐"><a href="#DaemonSet的调度和驱逐" class="headerlink" title="DaemonSet的调度和驱逐"></a>DaemonSet的调度和驱逐</h2><p>我们在集群中使用ds类型的时候会发现，当你部署ds的负载无论节点上有多少污点都可以调度上去，节点异常ds类型的pod也不发生驱逐，这是为什么呢？其实这里的根本原因也是因为ds类型的负载有添加污点的容忍，我们可以看下kube-proxy类型的ds容忍度是怎么设置的。</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">[root@VM_1_4_centos</span> <span class="string">kubernetes]#</span> <span class="string">kubectl</span> <span class="string">get</span> <span class="string">ds</span> <span class="string">kube-proxy</span> <span class="string">-n</span> <span class="string">kube-system</span> <span class="string">-o</span> <span class="string">yaml</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">extensions/v1beta1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">DaemonSet</span></span><br><span class="line"><span class="string">......</span></span><br><span class="line">      <span class="attr">serviceAccount:</span> <span class="string">kube-proxy</span></span><br><span class="line">      <span class="attr">serviceAccountName:</span> <span class="string">kube-proxy</span></span><br><span class="line">      <span class="attr">terminationGracePeriodSeconds:</span> <span class="number">30</span></span><br><span class="line">      <span class="attr">tolerations:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">operator:</span> <span class="string">Exists</span></span><br><span class="line">      <span class="attr">volumes:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">hostPath:</span></span><br></pre></td></tr></table></figure><p>从上面的yaml中可以看出ds类型容忍度是：空的 key 如果再配合 Exists 就能匹配所有的 key 与 value，也是是能容忍所有 node 的所有 Taints</p><p>所以这也就是为什么ds类型的pod不会发生驱逐和能调度到所有节点的原因，因为ds类型容忍所有污点。</p><h1 id="TKE上的调度实践"><a href="#TKE上的调度实践" class="headerlink" title="TKE上的调度实践"></a>TKE上的调度实践</h1><p>我们在tke集群中如果要配置调度策略，除了修改编写yaml实现，也可以在控制台进行操作，这样对于一些yaml不是很熟悉的同学可以提供更加简便的配置方式。</p><p><img src="2.png" alt="upload-image"></p><p><img src="3.png" alt="upload-image"></p><p><img src="4.png" alt="upload-image"></p><p><img src="5.png" alt="upload-image"></p><p>控制台支持配置3种策略，分别是不使用调度策略、指定节点调度（nodeSelector）、自定义调度策略（节点亲和性），这里控制台不能配置pod的亲和性和反亲和性，如果需要配置只能通过yaml配置。</p><p>如果需要修改已经部署的deployment的调度策略可以通过depolyment的更新调度策略来修改调整</p><p><img src="6.png" alt="upload-image"></p><p><img src="7.png" alt="upload-image"></p><p>对于pod的亲和性和反亲和性如何配置，大家可以参考集群中的coredns来进行配置</p><figure class="highlight less"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">apiVersion</span>: apps/v1beta2</span><br><span class="line"><span class="attribute">kind</span>: Deployment</span><br><span class="line"><span class="attribute">metadata</span>:</span><br><span class="line">  <span class="attribute">annotations</span>:</span><br><span class="line">    deployment.kubernetes.io/<span class="attribute">revision</span>: <span class="string">"1"</span></span><br><span class="line">  <span class="attribute">generation</span>: <span class="number">1</span></span><br><span class="line">  <span class="attribute">labels</span>:</span><br><span class="line">    addonmanager.kubernetes.io/<span class="attribute">mode</span>: Reconcile</span><br><span class="line">    <span class="attribute">k8s-app</span>: kube-dns</span><br><span class="line">    kubernetes.io/<span class="attribute">cluster-service</span>: <span class="string">"true"</span></span><br><span class="line">    kubernetes.io/<span class="attribute">name</span>: CoreDNS</span><br><span class="line">  <span class="attribute">name</span>: coredns</span><br><span class="line">  <span class="attribute">namespace</span>: kube-system</span><br><span class="line"><span class="attribute">spec</span>:</span><br><span class="line">......</span><br><span class="line">    <span class="attribute">spec</span>:</span><br><span class="line">      <span class="attribute">affinity</span>:</span><br><span class="line">        <span class="attribute">podAntiAffinity</span>:</span><br><span class="line">          <span class="attribute">requiredDuringSchedulingIgnoredDuringExecution</span>:</span><br><span class="line">          - <span class="attribute">labelSelector</span>:</span><br><span class="line">              <span class="attribute">matchExpressions</span>:</span><br><span class="line">              - <span class="attribute">key</span>: k8s-app</span><br><span class="line">                <span class="attribute">operator</span>: In</span><br><span class="line">                <span class="attribute">values</span>:</span><br><span class="line">                - kube-dns</span><br><span class="line">            <span class="attribute">topologyKey</span>: kubernetes.io/hostname</span><br><span class="line">      <span class="attribute">containers</span>:</span><br><span class="line">      - <span class="attribute">args</span>:</span><br><span class="line">        - -conf</span><br><span class="line">        - /etc/coredns/Corefile</span><br><span class="line">        <span class="attribute">image</span>: ccr.ccs.tencentyun.com/library/<span class="attribute">coredns</span>:<span class="number">1.2</span>.<span class="number">2</span></span><br></pre></td></tr></table></figure><h1 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h1><p><a href="https://kubernetes.io/zh/docs/concepts/scheduling-eviction/taint-and-toleration/" target="_blank" rel="noopener">https://kubernetes.io/zh/docs/concepts/scheduling-eviction/taint-and-toleration/</a></p><p><a href="https://www.qikqiak.com/post/kubernetes-affinity-scheduler/" target="_blank" rel="noopener">https://www.qikqiak.com/post/kubernetes-affinity-scheduler/</a></p><hr><ul class="pager"><li class="previous"><a href="/2020/08/27/Use-of-Kubectl-command-line-jsonpath/" data-toggle="tooltip" data-placement="top" title="Kubectl命令行jsonpath的使用">&larr; Previous Post</a></li><li class="next"><a href="/2020/08/23/RBAC-permission-management-of-Kubernetes/" data-toggle="tooltip" data-placement="top" title="Kubernetes之RBAC权限管理">Next Post &rarr;</a></li></ul><div class="comment_notes_blank"></div><div class="visitor_notice"><img src="/img/notice.png" alt="notice" title="notice"><p class="notice">欢迎访问 <a href="https://www.niewx.cn" target="Vashon">Vashon</a> 的博客，博客和文章在完善中，请大家耐心等待。 若有问题或者有好的建议欢迎留言，笔者看到之后会及时回复。</p></div><div class="comment_notes"><p></p></div><link rel="stylesheet" href="../../../../css/music-player/fonts/iconfont.css"><link rel="stylesheet" href="../../../../css/music-player/css/reset.css"><link rel="stylesheet" href="../../../../css/music-player/css/player.css"><div class="music-player"><audio class="music-player__audio"></audio><div class="music-player__main"><div class="music-player__blur"></div><div class="music-player__disc"><div class="music-player__image"><img width="100%" src="" alt=""></div><div class="music-player__pointer"><img width="100%" src="/img/cd_tou.png" alt=""></div></div><div class="music-player__controls"><div class="music__info"><h3 class="music__info--title">...</h3><p class="music__info--singer">...</p></div><div class="player-control"><div class="player-control__content"><div class="player-control__btns"><div class="player-control__btn player-control__btn--prev"><i class="iconfont icon-prev"></i></div><div class="player-control__btn player-control__btn--play"><i class="iconfont icon-play"></i></div><div class="player-control__btn player-control__btn--next"><i class="iconfont icon-next"></i></div><div class="player-control__btn player-control__btn--mode"><i class="iconfont icon-loop"></i></div></div><div class="player-control__volume"><div class="control__volume--icon player-control__btn"><i class="iconfont icon-volume"></i></div><div class="control__volume--progress player_progress"></div></div></div><div class="player-control__content"><div class="player__song--progress player_progress"></div><div class="player__song--timeProgess nowTime">00:00</div><div class="player__song--timeProgess totalTime">00:00</div></div></div></div></div></div><script src="../../../../js/music-player/utill.js"></script><script src="../../../../js/music-player/jquery.min.js"></script><script src="../../../../js/music-player/player.js?library=netease&music=https://kg.qq.com/node/play?s=7deFpz7Z26Jmv7di&g_f=share_html"></script><div class="social-share" data-wechat-qrcode-helper="" align="center"></div><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/social-share.js/1.0.16/css/share.min.css"><script src="https://cdnjs.cloudflare.com/ajax/libs/social-share.js/1.0.16/js/social-share.min.js"></script><hr><div id="lv-container" data-id="city" data-uid="MTAyMC80NzQ3MS8yMzk3MQ=="><script type="text/javascript">!function(e,t){var n=e.getElementsByTagName(t)[0];"function"!=typeof LivereTower&&((t=e.createElement(t)).src="https://cdn-city.livere.com/js/embed.dist.js",t.async=!0,n.parentNode.insertBefore(t,n))}(document,"script")</script><noscript>为正常使用来必力评论功能请激活JavaScript</noscript></div></div><aside id="sidebar"><div id="toc" class="toc-article"><strong class="toc-title">Contents</strong><ol class="toc-nav"><li class="toc-nav-item toc-nav-level-1"><a class="toc-nav-link" href="#nodeSelector"><span class="toc-nav-number">1.</span> <span class="toc-nav-text">nodeSelector</span></a><ol class="toc-nav-child"><li class="toc-nav-item toc-nav-level-2"><a class="toc-nav-link" href="#添加标签到节点"><span class="toc-nav-number">1.1.</span> <span class="toc-nav-text">添加标签到节点</span></a></li><li class="toc-nav-item toc-nav-level-2"><a class="toc-nav-link" href="#添加-nodeSelector-字段到-Pod-配置中"><span class="toc-nav-number">1.2.</span> <span class="toc-nav-text">添加 nodeSelector 字段到 Pod 配置中</span></a></li><li class="toc-nav-item toc-nav-level-2"><a class="toc-nav-link" href="#k8s默认给节点打的标签"><span class="toc-nav-number">1.3.</span> <span class="toc-nav-text">k8s默认给节点打的标签</span></a></li></ol></li><li class="toc-nav-item toc-nav-level-1"><a class="toc-nav-link" href="#节点的亲和性和反亲和性"><span class="toc-nav-number">2.</span> <span class="toc-nav-text">节点的亲和性和反亲和性</span></a></li><li class="toc-nav-item toc-nav-level-1"><a class="toc-nav-link" href="#pod的亲和性和反亲和性"><span class="toc-nav-number">3.</span> <span class="toc-nav-text">pod的亲和性和反亲和性</span></a><ol class="toc-nav-child"><li class="toc-nav-item toc-nav-level-2"><a class="toc-nav-link" href="#podAffinity"><span class="toc-nav-number">3.1.</span> <span class="toc-nav-text">podAffinity</span></a></li><li class="toc-nav-item toc-nav-level-2"><a class="toc-nav-link" href="#podAntiAffinity"><span class="toc-nav-number">3.2.</span> <span class="toc-nav-text">podAntiAffinity</span></a></li></ol></li><li class="toc-nav-item toc-nav-level-1"><a class="toc-nav-link" href="#污点和容忍"><span class="toc-nav-number">4.</span> <span class="toc-nav-text">污点和容忍</span></a><ol class="toc-nav-child"><li class="toc-nav-item toc-nav-level-2"><a class="toc-nav-link" href="#节点添加和去除污点"><span class="toc-nav-number">4.1.</span> <span class="toc-nav-text">节点添加和去除污点</span></a></li><li class="toc-nav-item toc-nav-level-2"><a class="toc-nav-link" href="#pod容忍污点"><span class="toc-nav-number">4.2.</span> <span class="toc-nav-text">pod容忍污点</span></a></li><li class="toc-nav-item toc-nav-level-2"><a class="toc-nav-link" href="#多个污点的pod容忍策略"><span class="toc-nav-number">4.3.</span> <span class="toc-nav-text">多个污点的pod容忍策略</span></a></li><li class="toc-nav-item toc-nav-level-2"><a class="toc-nav-link" href="#NoExecute类型pod继续运行时间"><span class="toc-nav-number">4.4.</span> <span class="toc-nav-text">NoExecute类型pod继续运行时间</span></a></li><li class="toc-nav-item toc-nav-level-2"><a class="toc-nav-link" href="#节点发生异常pod发生驱逐的原理"><span class="toc-nav-number">4.5.</span> <span class="toc-nav-text">节点发生异常pod发生驱逐的原理</span></a></li><li class="toc-nav-item toc-nav-level-2"><a class="toc-nav-link" href="#DaemonSet的调度和驱逐"><span class="toc-nav-number">4.6.</span> <span class="toc-nav-text">DaemonSet的调度和驱逐</span></a></li></ol></li><li class="toc-nav-item toc-nav-level-1"><a class="toc-nav-link" href="#TKE上的调度实践"><span class="toc-nav-number">5.</span> <span class="toc-nav-text">TKE上的调度实践</span></a></li><li class="toc-nav-item toc-nav-level-1"><a class="toc-nav-link" href="#参考链接"><span class="toc-nav-number">6.</span> <span class="toc-nav-text">参考链接</span></a></li></ol></div></aside><div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1 sidebar-container"><section><h5><a href="/tags/">FEATURED TAGS</a></h5><div class="tags"><a class="tag" href="/tags/#Kubernetes" title="Kubernetes">Kubernetes</a></div></section><hr><h5>FRIENDS</h5><ul class="list-inline"><li><a href="https://cloud.tencent.com/developer/column/87421" target="_blank">云+社区</a></li><li><a href="https://www.niewx.cn/mybook/" target="_blank">gitbook</a></li><li><a href="https://github.com/nieweixing" target="_blank">vashon&#39;s Github</a></li><li><a href="https://weibo.com/3264907804/profile?rig" target="_blank">weibo</a></li></ul></div></div></div></article><script>function async(e,n){var t=document,a="script",r=t.createElement(a),a=t.getElementsByTagName(a)[0];r.src=e,n&&r.addEventListener("load",function(e){n(null,e)},!1),a.parentNode.insertBefore(r,a)}</script><script>async("https://cdn.bootcss.com/anchor-js/1.1.1/anchor.min.js",function(){anchors.options={visible:"hover",placement:"left",icon:"ℬ"},anchors.add().remove(".intro-header h1").remove(".subheading").remove(".sidebar-container h5")})</script><style type="text/css">@media all and (min-width:800px){.anchorjs-link{position:absolute;left:-.75em;font-size:1.1em;margin-top:-.1em}}</style><footer><div class="container"><div class="row"><div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1"><ul class="list-inline text-center"><li><a target="_blank" href="https://github.com/nieweixing"><span class="fa-stack fa-lg"><i class="fa fa-circle fa-stack-2x"></i> <i class="fa fa-github fa-stack-1x fa-inverse"></i></span></a></li><li><a target="_blank" href="https://twitter.com/nieweixing"><span class="fa-stack fa-lg"><i class="fa fa-circle fa-stack-2x"></i> <i class="fa fa-twitter fa-stack-1x fa-inverse"></i></span></a></li><li><a target="_blank" href="https://www.facebook.com/nieweixing"><span class="fa-stack fa-lg"><i class="fa fa-circle fa-stack-2x"></i> <i class="fa fa-facebook fa-stack-1x fa-inverse"></i></span></a></li><li><a target="_blank" href="https://www.zhihu.com/people/ke-wang-mian-bao-de-you-xia"><span class="fa-stack fa-lg"><i class="fa fa-circle fa-stack-2x"></i> <i class="fa fa-stack-1x fa-inverse">知</i></span></a></li></ul><p class="copyright text-muted">Copyright &copy; 聂伟星 2021<br>Powered by <a href="https://github.com/dusign/hexo-theme-snail" target="_blank" rel="noopener"><i>hexo-theme-snail</i> </a>|<iframe name="star" style="margin-left:2px;margin-bottom:-5px" frameborder="0" scrolling="0" width="100px" height="20px" src="https://ghbtns.com/github-btn.html?user=dusign&repo=hexo-theme-snail&type=star&count=true"></iframe></p></div></div></div></footer><script src="../../../../js/jquery.min.js"></script><script src="../../../../js/bootstrap.min.js"></script><script src="../../../../js/hux-blog.min.js"></script><script src="../../../../js/search.js"></script><script>function async(e,n){var t=document,a="script",r=t.createElement(a),a=t.getElementsByTagName(a)[0];r.src=e,n&&r.addEventListener("load",function(e){n(null,e)},!1),a.parentNode.insertBefore(r,a)}</script><script>0!==$("#tag_cloud").length&&async("https://www.niewx.cn/js/jquery.tagcloud.js",function(){$.fn.tagcloud.defaults={color:{start:"#bbbbee",end:"#0085a1"}},$("#tag_cloud a").tagcloud()})</script><script>async("https://cdn.bootcss.com/fastclick/1.0.6/fastclick.min.js",function(){var c=document.querySelector("nav");c&&FastClick.attach(c)})</script><script>var _baId="bfe4709ccd8c5c9e559c89f4fd0866f3",_hmt=_hmt||[];!function(){var e=document.createElement("script");e.src="//hm.baidu.com/hm.js?"+_baId;var c=document.getElementsByTagName("script")[0];c.parentNode.insertBefore(e,c)}()</script><script type="text/javascript">var search_path="search.xml",path="/"+(search_path=0==search_path.length?"search.xml":search_path);searchFunc(path,"local-search-input","local-search-result")</script><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><a id="rocket" href="#top" class=""></a><script type="text/javascript" src="/js/totop.js?v=1.0.0" async=""></script><script type="text/javascript" src="/js/toc.js?v=1.0.0" async=""></script><script type="text/javascript" src="/js/mouse-click.js" content="[&quot;🌱&quot;,&quot;just do it&quot;,&quot;🍀&quot;]" color="[&quot;rgb(121,93,179)&quot; ,&quot;rgb(76,180,231)&quot; ,&quot;rgb(184,90,154)&quot;]"></script><script src="/js/ribbonDynamic.js"></script><script type="text/x-mathjax-config">MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ["$","$"], ["\\(","\\)"] ],
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
            processEscapes: true
        }
    });
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax();
        for (var i = 0; i < all.length; ++i)
            all[i].SourceElement().parentNode.className += ' has-jax';
    });</script><script src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({pluginRootPath:"live2dw/",pluginJsPath:"lib/",pluginModelPath:"assets/",tagMode:!1,log:!1,model:{jsonPath:"/live2dw/assets/z16.model.json"},display:{position:"left",width:250,height:500},mobile:{show:!0},react:{opacity:.7}})</script></body></html>